{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "机器学习三要素是：模型、策略、算法，下面介绍线性回归的三要素。其中模型这一步部分暂时只列出预测函数，后面将使用广义线性模型推导出模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性回归模型假设目标值$y^{(i)}$是特征$x^{(i)}$的线性组合，即${y}^{(i)}=\\theta^Tx^{(i)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性回归建立目标函数的策略是最大似然法，即假设真实值与预测值的误差服从高斯分布，且所有样本误差是独立同分布的，即$\\epsilon^{(i)}={y^{(i)}} - \\theta^Tx^{(i)}\\sim N(0, \\sigma^2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "假设由m个样本组成的特征矩阵为$X = (x^{(1)}, ...,x^{(i)},..., x^{(n)})^T$，由m个目标值组成的目标向量为$\\vec y = (y^{(1)},...,y^{(i)},...,y^{(n)})^T$,那么整个样本集的似然概率为: $$L(\\theta)=p(\\vec y \\mid X;\\theta)=\\prod_{i=1}^{m}{p(\\epsilon_{(i)})}=\\prod_{i=1}^{m}{\\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp {(-\\frac{(y^{(i)}-\\theta^Tx^{(i)})^2}{2\\sigma^2}})}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "模型的损失函数定义为: $$l(\\theta)=-log(p(\\vec y \\mid X; \\theta))=-\\sum_{i=1}^{m}{log \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp {(-\\frac{(y^{(i)}-\\theta^Tx^{(i)})^2}{2\\sigma^2}})}=mlog(\\sqrt{2\\pi}\\sigma)+\\frac{1}{2 \\sigma^2}\\sum_{i=1}^{m}{(y^{(i)}-\\theta^Tx^{(i)})^2} \\varpropto \\frac{1}{2}\\sum_{i=1}^{m}{(y^{(i)}-\\theta^Tx^{(i)})^2}=\\frac{1}{2}\\Arrowvert \\vec y - X\\theta \\Arrowvert_2^2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "线性回归的参数求解算法有两种，分别是梯度下降和牛顿法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "梯度下降法推导：$$\\frac{\\partial l(\\theta)}{\\partial \\theta}=\\sum_{i=1}^{m}(y^{(i)}-\\theta^T x^{(i)}) x^{(i)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里强调一下特征和参数都是向量。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "牛顿法推导采用直接对向量求导，推导如下：$$\\frac{\\partial l(\\theta)}{\\partial \\theta}=\\frac{1}{2}\\frac{\\partial ((\\vec y - X\\theta)^T(\\vec y - X\\theta))}{\\partial \\theta}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$=\\frac{1}{2}\\frac{\\partial (\\vec y^T \\vec y - \\vec y^T X\\theta - \\theta^TX^T\\vec y + \\theta^TX^TX\\theta)}{\\partial \\theta}=-2X^T \\vec y + 2X^TX\\theta$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "令$$-2X^T \\vec y + 2X^TX\\theta=0$$,得"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\theta = (X^TX)^{-1} X^T \\vec y$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里引用邹博线性代数中的求导公式：$$\\frac{\\partial A \\vec x}{\\partial \\vec x}=A^T$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial A \\vec x}{\\partial \\vec x^T} = (\\frac{\\partial A \\vec x}{\\partial \\vec x})^T = A$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial \\vec x^TA}{\\partial \\vec x} = \\frac{\\partial A^T \\vec x}{\\vec x}=A$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "所以 $$\\frac{\\partial \\vec y^T X\\theta}{\\partial \\theta} = X^T \\vec y$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial \\theta^TX^T\\vec y}{\\partial \\theta} = X^T \\vec y$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\frac{\\partial \\theta^TX^TX\\theta}{\\partial \\theta} = X^TX\\theta + X^TX\\theta = 2X^TX\\theta$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面分别使用梯度下降和牛顿法实现线性回归模型，首先设定权重向量w，然后使用w产生样本一定量样本，$X$和$y$，同时加入随机噪声，然后使用样本数据，通过算法学习新的参数$\\theta$，最后对比w和$\\theta$。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.3974024 , -0.84726581,  0.62868956, -0.22051104,  0.53331226])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w = np.random.randn(5) \n",
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.random((1000, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = X.dot(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta = "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
